#!/bin/bash

# Set variables
PATH_TO_TRANSFORMERS=$1

# Finetune checkpoint on tagged data
python3 $PATH_TO_TRANSFORMERS/examples/pytorch/translation/run_translation.py \
		--model_name_or_path wmt19-en-de \
		--do_train \
		--do_eval \
		--source_lang en \
		--target_lang de \
		--dataset_name wmt19-tagged \
		--dataset_config_name de-en \
		--load_from_disk \
		--output_dir finetuned_model_en-de \
		--per_device_train_batch_size 30 \
		--per_device_eval_batch_size 30 \
		--overwrite_output_dir \
		--predict_with_generate \
		--use_fast_tokenizer \
		--preprocessing_num_workers 20 \
		--fp16 \
		--num_train_epochs 1 \
		--save_total_limit 5 \
        --max_steps 50000

echo "Done. Finished finetuning on tagged data."
